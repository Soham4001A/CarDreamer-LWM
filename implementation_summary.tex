\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsfonts,booktabs,geometry,hyperref}
\usepackage{listings}
\geometry{margin=1in}
\newcommand{\code}[1]{\texttt{\detokenize{#1}}}

\begin{document}

{\LARGE \textbf{ArkAngel Implementation Summary (Revised)}}

\section{Introduction}
This document summarizes the implementation of the ArkAngel architecture into the DreamerV3 model within the CarDreamer project, as per the instructions provided in \code{Instructions.tex}. The implementation includes the addition of new model heads for future prediction, auxiliary losses for training, and an inference patching mechanism to handle partial observability. This revised summary reflects the corrections and improvements made based on user feedback.

\section{File Changes}

\subsection{\code{dreamerv3/nets.py}}
Two new modules, $g_{LA}$ and $g_{RA}$, were added to this file to implement the core of the ArkAngel prediction mechanism. The modules are implemented as \code{flax.linen.Module} subclasses, using the \code{@nn.compact} decorator.

\subsubsection{New Modules}
\begin{lstlisting}[language=Python]
from flax import linen as nn

class LatentActor(nn.Module):
    deter_size: int
    stoch_size: int
    classes: int | None = None
    mlp_layers: int = 4
    mlp_units: int = 512

    @nn.compact
    def __call__(self, h, z, a):
        if self.classes:
            z = z.reshape(z.shape[:-2] + (self.stoch_size * self.classes,))
        a = a.reshape(a.shape[:-1] + (-1,))
        x = jnp.concatenate([h, z, a], -1)
        for _ in range(self.mlp_layers):
            x = nn.relu(nn.Dense(self.mlp_units)(x))
        x = nn.Dense(self.deter_size + (self.stoch_size * (self.classes or 1)))(x)
        h_hat, z_flat = jnp.split(x, [self.deter_size], -1)
        if self.classes:
            z_hat = z_flat.reshape(z_flat.shape[:-1] + (self.stoch_size, self.classes))
        else:
            z_hat = z_flat
        return h_hat, z_hat


class ReconstructionActor(nn.Module):
    shape: tuple
    cnn_depth: int = 48
    cnn_blocks: int = 2
    resize: str = 'stride'
    minres: int = 4
    cnn_sigmoid: bool = False
    image_dist: str = 'mse'

    @nn.compact
    def __call__(self, h_hat, z_hat):
        if len(z_hat.shape) > 2: # classes
            z_hat = z_hat.reshape(z_hat.shape[:-2] + (z_hat.shape[-2] * z_hat.shape[-1],))
        x = jnp.concatenate([h_hat, z_hat], -1)
        mean = ImageDecoderResnet(
            self.shape, self.cnn_depth, self.cnn_blocks, self.resize, 
            minres=self.minres, sigmoid=self.cnn_sigmoid, name='ra_cnn'
        )(x)
        if self.image_dist == "normal":
            return tfd.Independent(tfd.Normal(mean, 1), 3)
        if self.image_dist == "mse":
            return jaxutils.MSEDist(mean, 3, "sum")
        raise NotImplementedError(self.image_dist)
\end{lstlisting}

\subsection{\code{dreamerv3/agent.py}}
This file was modified to integrate the new ArkAngel modules into the agent's lifecycle, including training and policy execution.

\subsubsection{WorldModel Modifications}
\begin{itemize}
    \item In \code{WorldModel.__init__}, the \code{LatentActor} and \code{ReconstructionActor} are instantiated and the loss scales for them are added.
    \item In \code{WorldModel.train}, the new heads are added to the list of modules to be optimized.
    \item In \code{WorldModel.loss}, the auxiliary losses $L_{LA}$ and $L_{RA}$ are computed and added to the total model loss. The loss for the discrete latent variable $z$ in $L_{LA}$ was corrected to use cross-entropy.
\end{itemize}

\subsubsection{Agent Modifications}
\begin{itemize}
    \item In \code{Agent.policy_initial}, the agent's state was updated to include the ArkAngel predictions and a blackout counter for multi-step blackout handling.
    \item In \code{Agent.policy}, the inference patching logic was implemented. This includes single-step patching for partially occluded frames and multi-step prediction rollout for complete blackouts (up to $patch_k$ steps). The patching logic was corrected to use the \code{.mode()} of the reconstruction distribution.
\end{itemize}

\subsection{\code{car_dreamer/toolkit/observer/utils.py}}
This file was modified to register the new \code{MaskHandler}.
\begin{lstlisting}[language=Python]
from enum import Enum

from .handlers import (
    BirdeyeHandler, CameraHandler, CollisionHandler, LidarHandler, MessageHandler, SpectatorHandler, MaskHandler
)


class HandlerType(Enum):
    """User-defiend data sources"""

    RGB_CAMERA = "camera"
    LIDAR = "lidar"
    COLLISION = "collision"
    BIRDEYE = "birdeye"
    MESSAGE = "message"
    SPECTATOR = "spectator"
    MASK = "mask"


HANDLER_DICT = {
    HandlerType.BIRDEYE: BirdeyeHandler,
    HandlerType.MESSAGE: MessageHandler,
    HandlerType.RGB_CAMERA: CameraHandler,
    HandlerType.LIDAR: LidarHandler,
    HandlerType.COLLISION: CollisionHandler,
    HandlerType.SPECTATOR: SpectatorHandler,
    HandlerType.MASK: MaskHandler,
}
\end{lstlisting}

\subsection{\code{run_dm3_sweep.sh}}
This shell script was updated to include a \code{DRY_RUN} flag and a sweep over transmission error rates.

\section{New Files Created}

\subsection{\code{car_dreamer/toolkit/observer/handlers/mask_handler.py}}
This file contains the \code{MaskHandler} class, which is responsible for generating a binary mask representing the agent's field of view.

\section{Placeholders and Limitations}

\subsection{LPIPS Loss}
The LPIPS (Learned Perceptual Image Patch Similarity) loss for $L_{RA}$ has been implemented as a placeholder. The current implementation uses a standard Mean Squared Error (MSE) instead of a true LPIPS metric.

\paragraph{Reasoning:}
A proper LPIPS implementation requires a pre-trained deep neural network (e.g., VGG, AlexNet) to be used as a feature extractor. My development environment does not allow me to add new dependencies or download pre-trained model weights. Therefore, I have added a placeholder to make it easy for you to integrate a proper LPIPS library.

\paragraph{Code Placeholder in \code{dreamerv3/agent.py}:}
\begin{lstlisting}[language=Python]
# ... in WorldModel.loss
if self.config.arkangel.lpips_weight > 0:
    # This is a placeholder for LPIPS loss.
    # A real LPIPS implementation would require a pre-trained network.
    # For now, we use MSE as a placeholder.
    o_hat_tp1 = o_hat_tp1_dist.mode()
    lpips_loss = ((o_hat_tp1 - o_tp1_target) ** 2).mean()
    ra_loss += self.config.arkangel.lpips_weight * lpips_loss
\end{lstlisting}

\section{How to Run}
To run the experiments, you can use the provided \code{run_dm3_sweep.sh} script. It can be run in two modes:
\begin{itemize}
    \item \textbf{Dry Run}: \code{./run_dm3_sweep.sh <carla_port> <gpu_id> true}. This will print the commands for each experiment without executing them.
    \item \textbf{Execution}: \code{./run_dm3_sweep.sh <carla_port> <gpu_id>}. This will execute the experiments.
\end{itemize}

\end{document}
